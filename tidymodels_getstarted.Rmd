---
title: "Tidymodels"
author: "Nabil"
date: "08/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(readr)
library(broom.mixed)
library(dotwhisker)

```

# Build a model

## Dados

Utilizaremos os dados sobre ouriços. Existem 3 tipos de regimes de alimentação que afetam o tamanho do ouriço ao longo do tempo. Além disso, o tamanho inicial do ouriço provavelmente também afeta o quanto eles crescem.

```{r}
urchins <-
  # Data were assembled for a tutorial 
  # at https://www.flutterbys.com.au/stats/tut/tut7.5a.html
  read_csv("https://tidymodels.org/start/models/urchins.csv") %>% 
  # Change the names to be a little more verbose
  setNames(c("food_regime", "initial_volume", "width")) %>% 
  # Factors are very helpful for modeling, so we convert one column
  mutate(food_regime = factor(food_regime, levels = c("Initial", "Low", "High")))

urchins
```
`food_regime` é o regime de alimentação experimental do grupo; `initial_volume` é o tamanho inicial em milimetros ;`widht` comprimento do ouriço no final do experimento

## Plot

O primeiro passo ao criar um modelo é plotar os dados.

```{r}
ggplot(urchins,
       aes(x = initial_volume, 
           y = width, 
           group = food_regime, 
           col = food_regime)) + 
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) +
  scale_color_viridis_d(option = "plasma", end = .7)+
  theme(legend.position = "top")
#> `geom_smooth()` using formula 'y ~ x'

```

Os dados mostram que ouriços com um volume inicial maior cresceram mais que aqueles que tinham um volume inicial menor. Além disso, o modelo linear mostra inclinações diferentes a depender do regime do ouriço


## Construir e montar um modelo

Sabemos que temos duas variáveis continuas e uma categórica o modelo `ANOVA` de variância bidirecional, serve para a análise.

Dado que a inclinação aparenta ser diferente ao menos entre dois regimes construimos o modelo de interação  bidirecional abaixo

` width ~ initial_volume * food_regime `

Para esse modelo, MQO parece servis. Através do pacote `parsnip` podemos criar um modelo linar dado que o resultado é numerico e o modelo deve ser linear com inclinações e intercepto.

`linear_reg()`

Agora que o tipo de modelo foi especificado podemos criar um método que monte e treine o modelo, utilizando o mecanismo `lm` que utiliza MQO.


```{r}
lm_mod <- linear_reg() %>% 
   set_engine("lm")
```

Após criar o objeto, o modelo pode ser estimado ou treinado utilizando a função `fit()`

```{r}
lm_fit <- 
  lm_mod %>% 
  fit(width ~ initial_volume * food_regime, data = urchins)
lm_fit

```

Para descrever o resultado do modelo acima podemos utilizar a função `tidy()` que resulta em um summary mais preditivo e um formato mais útil.

```{r}
tidy(lm_fit)

```

O sumário acima pode ser plotado utilizando o pacote `dotwhisker`

O gráfico acima verifica a variância, nota-se que food_regime Low e High são estatísticamente igual a 0. Mas, ao interagir com o volume inicial torna-se significativo o regime Low. 

```{r}
tidy(lm_fit) %>% 
  dwplot(dot_args = list(size = 2, color = "black"),
         whisker_args = list(color = "black"),
         vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))

```

## Utilizando o modelo para previsões

O modelo estimado por ser adquirido a partir de `lm_fit$fit`. Supondo que os ouriços tenham o tamanho inicial de 20, com regimes diferentes, criaremos o data.frame abaixo.

```{r}
new_points <- expand.grid(initial_volume = 20, 
                          food_regime = c("Initial", "Low", "High"))
new_points

```
É possível adquirir os resultados, utilizando a função `predict()`. Primeiramente geraremos os valores finais médios preditos. 


```{r}
mean_pred <- predict(lm_fit, new_data = new_points)
mean_pred

```
Ao criar previsões, tidymodels produz nomes padrões de coluna. Criaremos agora o intervalo de confiança dado os valores médios finais preditos.

```{r}
conf_int_pred <- predict(lm_fit, 
                         new_data = new_points, 
                         type = "conf_int")
conf_int_pred
```
Agora jutanremos os valores previstos médios e o intervalo de confiança e por fim geraremos o gráfico.

```{r}
plot_data <- 
  new_points %>% 
  bind_cols(mean_pred) %>% 
  bind_cols(conf_int_pred)

# and plot:
ggplot(plot_data, aes(x = food_regime)) + 
  geom_point(aes(y = .pred)) + 
  geom_errorbar(aes(ymin = .pred_lower, 
                    ymax = .pred_upper),
                width = .2) + 
  labs(y = "urchin size")
```
## Modelo com mecanismo diferente `(!= lm)`.

Utilizaremos uma abordagem bayesiana. Para essa análise, precisamos declarar a distribuição do modelo, utilizaremos uma distribuição conservadora, Cauchy distribution. `linear_reg()` tem o meanismo stan que estima o modelo.

Análise bayesiana utiliza dados randomicos, usaremos a função `set.seed()` pque geram numeros pseudo-random (reproduzir análise). 

```{r}
# set the prior distribution
prior_dist <- rstanarm::student_t(df = 1)

set.seed(123)

# make the parsnip model
bayes_mod <-   
  linear_reg() %>% 
  set_engine("stan", 
             prior_intercept = prior_dist, 
             prior = prior_dist) 

# train the model
bayes_fit <- 
  bayes_mod %>% 
  fit(width ~ initial_volume * food_regime, data = urchins)

print(bayes_fit, digits = 5)

```
A função `tidy()` é possível tabelas os resultados.

```{r}
tidy(bayes_fit, conf.int = TRUE)
```

Plotando os valores previstos, dado o valor inicial de 20.

```{r}
bayes_plot_data <- 
  new_points %>% 
  bind_cols(predict(bayes_fit, new_data = new_points)) %>% 
  bind_cols(predict(bayes_fit, new_data = new_points, type = "conf_int"))

ggplot(bayes_plot_data, aes(x = food_regime)) + 
  geom_point(aes(y = .pred)) + 
  geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper), width = .2) + 
  labs(y = "urchin size") + 
  ggtitle("Bayesian model with t(1) prior distribution")

```
Conclui-se que a diferença entre stan e lm não é muito visível.

#  Preprocess your data with recipes

## introdução

Ao criar o modelo utilizamos modelos diferentes utilizando o pacote `parsnip`.  O pacote `recipes` permite diferentes processamentos e etapas antes de treinar os modelos, como:

1. Crianção de Dummies

2. Reescalar as variáveis

3. transformar um grupo de estimadores

4. extrair valores importantes dos dados

E muito mais.

## Dados dos voos de Nova York

```{r}
# Helper packages
library(nycflights13)    # for flight data
library(skimr)           # for variable summaries
```

Para exemplo, utilizaremos os dados do `nycflights13data` para prever se os voos chegarão com mais de 30 minutos atrasados. Os dados são de 2013 e contém 325.819 voos partindo de Nova York. Vamos carregar os dados e fazer algumas modificações.

```{r}
set.seed(123)

flight_data <- 
  flights %>% 
  mutate(
    # criando a variável de atraso
    arr_delay = ifelse(arr_delay >= 30, "late", "on_time"),
    arr_delay = factor(arr_delay),
    # criar variável de data
    date = lubridate::as_date(time_hour)
  ) %>% 
  # incluir variável clima
  inner_join(weather, by = c("origin", "time_hour")) %>% 
  # selecionando as variáveis de interesse
  select(dep_time, flight, origin, dest, air_time, distance,
         carrier, date, arr_delay, time_hour) %>% 
  # limpando NA's
  na.omit() %>% 
  # mudando strings para factor
  mutate_if(is.character,as.factor)
```

16% dos voos chegaram atrasados com mais de 30 minutos.

```{r}
flight_data %>% 
  count(arr_delay) %>% 
  mutate(prop = n/sum(n))
```

Antes de começarmos a criar o `recipe` vamos analisar algumas variáveis específicas. Dado que a variável `arr_delay` é um `factor` o nosso modelo será logistico.

```{r}
glimpse(flight_data)
```

As variáveis `flight` e `time_hour` não serão variáveis preditivas mas serão úteis para identificação de dados problematicos

Resumo dos destinos e companhias.
```{r}
flight_data %>% 
  skimr::skim(dest, carrier) 
```
A tabela acima diz que existem 104 destinos e 16 companhias aéreas, já que queremos fazer um modelo logit, essas variáveis categoricas precisam ser convertidas para Dummies, porém, temos muitas opções e algumas podem ser bem mais frequentes que outras. Discutiremos a seguir como lidar com esse "problema".

## Data Splitting

Data split basicamente é separar uma proporção dos dados para treinar o modelo (calcular os estimadores) e outra parte para testar os estimadores. Para realizarmos essa separação utilizamos as funções do pacot `rsample`.

```{r}
set.seed(222)

# separando em 3/4
data_split <- initial_split(flight_data, prop = 3/4)

# criando os data.frames
train_data <- training(data_split)
test_data <- testing(data_split)

```

## Criando Recipe(Receita) e papeis.

Criaremos agora recita para regressão logit simples. Antes de treinarmos o modelo criaremos receitas para criar novas variáveis e alguns processamento.

```{r}
flights_rec <- 
  recipe(arr_delay ~., data = train_data)
```

A função `recipe()` possui dois argumentos.

1. Formula: o lado esquerdo do tio (~) é a variavel dependente e do lado direito as variáveis independentes, "." significa todas outras variáveis, é possível indicar apenas alguns.

2. Dados: para o `recipe()` usualmente é utilizado os dados de treinamento.

Feito isso, podemos adicionar papeis as variáveis do recipes, utilizando a função `update_role()`. Nesse exemplo atribuiremos as variáveis `flight` e `time_hour`, como variáveis de identificações `ID`.

```{r}
flights_rec <-
  recipe(arr_delay ~ ., data = train_data) %>% 
  update_role(flight, time_hour, new_role = "ID")
```

Adicionar papeis as variáveis é optional mas permite que as variáveis presentes na base não seja incluída no modelo.

Para resumir os papeis de cada variável é possível utilizar a função `summary()`

```{r}
summary(flights_rec)
```
## Criando recursos
É possível criar passos (step) nos recipes utilizando o pipe. É razoável que os atrasos tenham relação com a época do ano. É possível transformar a data em numérico para incluirmos no modelo. Podemos também extrair algumas variáveis derivada da data como o dia da semana, mês ou se é feriado. 

É possível fazer tudo isso com as funções abaixo:

```{r}
flights_rec <- 
  recipe(arr_delay ~ ., data = train_data) %>% 
  # dow = day of the week
  step_date(date, features = c("dow", "month")) %>%
  # feriados
  step_holiday(date,
               holidays = timeDate::listHolidays("US"),
               keep_original_cols = FALSE)
```


Portanto, `step_date` extraimos o dia da semana e o mes do ano de acordo com a data. Os feriados utilizamos a função `step_holiday`.

Agora vamos observar os tipos de variaveis independentes. Precisamos transformar nossas variáveis factor em numericas para incluí-las no modelo logit. Portanto, criaremos dummies derivadas dessas variáveis.

```{r}
flights_rec <-
  recipe(arr_delay ~ ., data = train_data) %>% 
  update_role(flight, time_hour, new_role = "ID") %>% 
  step_date(date, features = c("dow", "month")) %>%
  step_holiday(date,
               holidays = timeDate::listHolidays("US"),
               keep_original_cols = FALSE) %>% 
  # transformando todas as variáveis string e factor para dummies
  step_dummy(all_nominal_predictors())
```

Por fim, verificamos se há alguma infrequência ocorrida pelas variáveis categoricas criando dummies que não estão presentes em uma das bases. Por exemplo, o destino `LEX` está presente apenas na base de teste como mostra abaixo

```{r}
test_data %>% 
  distinct(dest) %>% 
  anti_join(train_data)
```

Por isso é importante utilizamos a função `step_zv()` que remove colunas que contem apenas um único valor. 

```{r}
flights_rec <-
  recipe(arr_delay ~ ., data = train_data) %>% 
  update_role(flight, time_hour, new_role = "ID") %>% 
  step_date(date, features = c("dow", "month")) %>%
  step_holiday(date,
               holidays = timeDate::listHolidays("US"),
               keep_original_cols = FALSE) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())

```


## Rodando o modelo com Recipe

Antes de passar os dados para o modelo, especificamos o modelo com pacote `parsnip`.

```{r}
lr_mod <-
  logistic_reg() %>% 
  set_engine("glm")
```

Especificando o modelo de regressão podemos processar o `recipe()` utilizando os dados de treinamento e para os dados de teste.

Para simplificar, podemos criar um modelo de workflow que une o modelo e a receita.

```{r}
flights_wflow <-
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(flights_rec)

flights_wflow
```

Criado o workflow podemos treinar o modelo.

```{r}
flights_fit <-
  flights_wflow %>% 
  fit(data = train_data)
```

Uma vez treinado podemos extrair os coeficientes ou os objetos da receita. Para fazer isso é só utilizar as funções `extract_fit_parsnip()` e `extract_recipe()`. No exemplo abaixo extraimos os coeficientes com `tidy()`

```{r}
flights_fit %>% 
  extract_fit_parsnip() %>% 
  tidy()
```

## Utilizando o workflow para predição

Criamos o modelo, processamos a receita, criamos o workflow e por último treinamos o modelo. Agora vamos prever utilizando a base de dado de teste com a função `predict()`

```{r}
predict(flights_fit, test_data)
```
Dado que o a variável dependente é um fator, a predição será do mesmo formato. Apesar disso, podemos extrair a probabilidade de pertencer ao fator. Podemos utilizar isso com a função `predict(..., type = "prob")` ou utilizar a função `augment()`.

```{r}
flights_aug <-
  augment(flights_fit, test_data)
```

```{r}
flights_aug %>% 
  select(arr_delay, time_hour, flight, .pred_class, .pred_on_time)
```

Agora que temos as predições podemos avaliar a performance do modelo. Podemos verificar a `ROC curve` como métrica de avaliação. A curva possui como eixos o `falso positivo x positivo verdadeiro`.

```{r}
flights_aug %>% 
  roc_curve(truth = arr_delay, .pred_late) %>% 
  autoplot()
```

Similar ao `roc_curve`, `roc_auc()` estima a área abaixo da curva

```{r}
flights_aug %>% 
  roc_auc(truth = arr_delay, .pred_late)
```

# Avaliando o modelo com Resampling

Aprendemos a criar um modelo e processar os dados com `recipe` antes de testar o modelo.
Uma vez que temos o modelo treinado precisamos de medidas que avaliam a qualidade dos valores preditos. Podemos fazer isso baseado em reamostragem estatística.

Para esse exemplo de resampling utilizaremos dados de imagem de celulas. Queremos prever a classe das celulas de acordo com os dados.

```{r}
data(cells, package = "modeldata")
cells
```

Queremos prever quais celulas foram bem segmentadas ou mal segmentadas para melhorar a qualidade da base de dados final. 

Portanto, a base possui a variável class com dois fatores: PS (mal segmentada) e WS (bem segmentada). Além disso, a base possui mais 56 variaveis independente baseado em medidas através de análise de imagem automatizada.

Percebe-se que a base é desbalanceada, possui mais celulas mal segmentada do que bem segmentada.

```{r}
cells %>% 
  count(class) %>% 
  mutate(prop = n/sum(n))
```

## Data Splitting

Separando a base em treino e teste.

```{r}
set.seed(123)

cell_split <- initial_split(cells %>% select(-case),
                            strata = class)
```

Utilizamos o argumento `strata =` para que a proporção fiquem igual entre os dados de treino e de teste. 

Feito o split inicial separamos as bases. 75% para treino e 25% para teste

```{r}
cell_train <- training(cell_split)
cell_test <- testing(cell_split)
```

Verificando se as proporções se mantiveram entre as bases de treino e teste

```{r}

# proporção das classes da base de treino
cell_train %>% 
  count(class) %>% 
  mutate(prop = n/sum(n))

# proporção das classes da base de teste
cell_test %>% 
  count(class) %>% 
  mutate(prop = n/sum(n))
```

## Modelando

Iremos utilizar o modelo de `Random Forest`. Um dos benefícios do Random Forest é que requer muito pouco manipulação dos dados.  Por isso, não iremos criar receita (`Recipe`).

Em contra partida, o numero de arvores deve ser grande ( > 1000) fazendo o modelo ser exaustivo para os computadores. Portanto, para gerar o modelo com a base de dados de treino usaremos o pacote `parsnip` com a máquina `Ranger`.

```{r}
rf_mod <-
  rand_forest(trees = 100) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")
```


```{r}

```




